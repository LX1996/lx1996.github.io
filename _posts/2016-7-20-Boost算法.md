---
title: Boost算法
updated: 2016-07-20 11:28
---
**1.名词解释**

Boost(推进)，adaboost（adapt boost）自适应推进算法：Adaboost算法是机器学习中一种比较重要的特征分类算法，已被广泛应用人脸表情识别、图像检索等应用中。就目前而言，对Adaboost算法的研究以及应用大多集中于分类问题，在一些回归问题上也有所应用。Adaboost主要解决的问题有: 两类问题、多类单标签问题、多类多标签问题、回归问题。

**2.强学习算法与弱学习算法**

在机器学习领域，Boosting算法是一种通用的学习算法，这一算法可以提升任意给定的学习算法的性能。其思想源于1984年Valiant提出的”可能近似正确”-PAC(Probably Approximately Correct)学习模型，在PAC模型中定义了两个概念-强学习算法和弱学习算法。其概念是: 如果一个学习算法通过学习一组样本，识别率很高，则称其为强学习算法;如果识别率仅比随机猜测略高，其猜测准确率大于50，则称其为弱学习算法。

**3.Boost与 adaBoost算法的训练**

Boosting分类方法，其过程如下所示：

1）先通过对N个训练数据的学习得到第一个弱分类器h1；

2）将h1分错的数据和其他的新数据一起构成一个新的有N个训练数据的样本，通过对这个样本的学习得到第二个弱分类器h2；

3）将h1和h2都分错了的数据加上其他的新数据构成另一个新的有N个训练数据的样本，通过对这个样本的学习得到第三个弱分类器h3；

4）最终经过提升的强分类器h_final=Majority Vote(h1,h2,h3)。即某个数据被分为哪一类要通过h1,h2,h3的多数表决。

上述Boosting算法，存在两个问题：

①如何调整训练集，使得在训练集上训练弱分类器得以进行。

②如何将训练得到的各个弱分类器联合起来形成强分类器。

 

针对以上两个问题，AdaBoost算法进行了调整：

①使用加权后选取的训练数据代替随机选取的训练数据，这样将训练的焦点集中在比较难分的训练数据上。

②将弱分类器联合起来时，使用加权的投票机制代替平均投票机制。让分类效果好的弱分类器具有较大的权重，而分类效果差的分类器具有较小的权重。


AdaBoost算法的流程：

![image](http://stblog.baidu-tech.com/wp-content/uploads/wp-display-data.php?filename=image00112953418311302596098.png&type=image%2Fpng&width=672&height=493)

