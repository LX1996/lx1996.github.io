---
title: Bagging与随机森林
updated: 2016-07-20 15:10
---

**1.Bagging**

Bagging是并行式集成学习算法的代表。它是基于自助采样法(bootstrap sampling)来提高学习器泛化能力的一种高效的集成学习方法。

Bagging的策略：

1。从样本集D中用bootstrap采样选出n个样本，执行m次，选出m个样本子集。

2。在所有属性上，分别对应这m个样本子集建立m 个学习器。

3.将这m个学习器放在各自的训练数据上进行学习。

4.通过投票法或平均法对这m个学习器进行结合。



**2.随机森林**

随机森林（Random Forest）是Bagging的一个扩展变体，RF在以决策树为基学习器构建Bagging的基础上，进一步在决策树的训练过程中引入了随机属性的选择。

1）从样本集中用Bootstrap采样选出n个样本

2）在树的每个节点上，从所有属性中随机选择k个属性，选择出一个最佳分割属性作为节点,建立决策树，k一般选为log2d,d表示属性的总个数

3）重复以上两步m次，建立m棵决策数

4）这m棵决策树形成RandomForest

随机森林中基学习器的多样性不仅来自样本扰动，还来自属性的扰动，因此最终集成的泛化性能有显著的提高。


**3.结合策略**

3.1 平均法

3.1.1 简单平均法(simple averaging)

3.1.2 加权平均法(weighted averaging)

3.2 投票法

3.2.1 绝对多数投票法

3.2.2 相对多数投票法

3.2.3 加权投票法

3.3 学习法


