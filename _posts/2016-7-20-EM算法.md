---
title: EM算法
updated: 2016-07-20 20:50
---
**一.几个概念**

1.凸集：对于集合C，若c中任意的两点的连线都在c内，则称c是一个凸集。

2，凸函数： 函数f是凸的，如果f''(x) >＝ 0

3.凸(convex)与凹(concave)

logx, lnx是严格 concave的

ax + b即是convex的又是concave的

exp(ax) 是convex的

**二.Jensen's inequality**

Jensen不等式表述如下：

如果f是凸函数，X是随机变量，那么

![image](http://images.cnblogs.com/cnblogs_com/jerrylead/201104/201104061615543296.png)

特别地，如果f是严格凸函数，那么![image](http://images.cnblogs.com/cnblogs_com/jerrylead/201104/201104061615543296.png)当且仅当![image](http://images.cnblogs.com/cnblogs_com/jerrylead/201104/201104061615555871.png)

当f是凹函数时，-f是凸函数

Jensen不等式应用于凹函数时，不等号方向反向，也就是![image](http://images.cnblogs.com/cnblogs_com/jerrylead/201104/201104061615577530.png)


**三。EM 算法**

1. EM 算法 通过引入隐含项，用MLE进行了参数迭代求解。

2. 每次迭代过程有两步，Expectation 和 Maximization

	E-step： 通过observed data 和现有模型估计参数估计 missing data。
	
	M-step:  假设missing data已知的情况下最大化似然函数。
	
	由于算法保证了每次迭代 likelihood单调递增，所以该算法收敛。
	
3. 

![image](http://images.cnblogs.com/cnblogs_com/jerrylead/201104/201104061616069601.png)


4 一般 EM  算法的步骤

循环重复直到收敛 {


   （E步）对于每一个i，计算
      
   ![image](http://images.cnblogs.com/cnblogs_com/jerrylead/201104/201104061616324817.png)
   
   (M步)计算：
   
   ![image](http://images.cnblogs.com/cnblogs_com/jerrylead/201104/201104061616321295.png)
   
   
      
**四。EM算法的关键问题**

证明收敛：

![image](http://images.cnblogs.com/cnblogs_com/jerrylead/201104/201104061616388824.png)

![image](http://images.cnblogs.com/cnblogs_com/jerrylead/201104/201104061616434369.png)








